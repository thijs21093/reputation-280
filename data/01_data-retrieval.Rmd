---
title: "01_data-retrieval"
author: "Moritz MÃ¼ller"
date: "10/20/2021"
output: html_document
---
# Load Twitter handles + libraries
```{r}
handles =read.csv(file="handles.csv", sep=";")
handles[26,] = c("ELA", "European Union Labour Authority", "@EU_ELA", "https://twitter.com/EU_ELA", "1-6-2019")
write.csv(handles, file="handles.csv")

library(academictwitteR)
```


# Get Tweets
```{r}

#store various agency tweet databases in one list
alltweets = list()

#cycle through handles and save tweets to alltweets
for (i in 1:nrow(handles)) {
  print(handles$twitter_handle[i])
  agencytweets = get_all_tweets(
    user = substring(handles$twitter_handle[i], 2),
    start_tweets = "2007-01-01T00:00:00Z",
    end_tweets = "2021-12-31T00:00:00Z",
    bearer_token = get_bearer(),
    data_path = "data_tweets_3",
    bind_tweets = T,
    n=1000000
  )
  agencytweets$agencyhandle = handles$twitter_handle[i]
  agencytweets$agencyname = handles$acronym[i]
  alltweets[[i]] = agencytweets
}


save(alltweets, file = "data_tweets_3/alltweets3")

```
# Bind all tweets to a dataframe
```{r}
test$referenced_type = "no reference"
test$referenced_id = 0

for(i in 1:nrow(test)){
  test$referenced_type[i] = ifelse(is.null(test$referenced_tweets[i][[1]])==F, test$referenced_tweets[i][[1]]$type, 0)
  test$referenced_id[i] = ifelse(is.null(test$referenced_tweets[i][[1]])==F, test$referenced_tweets[i][[1]]$id, 0)
}

# now for the whole list of tweets
tweets = list()
for(f in 1:length(alltweets)){
  temporary = alltweets[[f]]
  temporary$referenced_type = "no reference"
  temporary$referenced_id = 0
  for(i in 1:nrow(temporary)){
    temporary$referenced_type[i] = ifelse(is.null(temporary$referenced_tweets[i][[1]])==F, temporary$referenced_tweets[i][[1]]$type, 0)
    temporary$referenced_id[i] = ifelse(is.null(temporary$referenced_tweets[i][[1]])==F, temporary$referenced_tweets[i][[1]]$id, 0)
    tweets[[f]] = temporary
  }
}

save(tweets, file="tweets")
```

# Manipulation and formating
```{r}
#test dataset
test$RT = grepl("RT ", test$text, fixed=TRUE)
test$date = as.POSIXct(test$created_at,
                    format = "%Y-%m-%dT%H:%M:%S.000Z")
test$text_clean = sapply(test$text,function(row) iconv(row, "latin1", "ASCII", sub=""))

#EFSA network chatter
EFSA_tweetcounts$start = as.POSIXct(EFSA_tweetcounts$start,
                    format = "%Y-%m-%dT%H:%M:%S.000Z")
EFSA_tweetcounts$end = as.POSIXct(EFSA_tweetcounts$end,
                    format = "%Y-%m-%dT%H:%M:%S.000Z")

```

# Get replies
```{r}
# store various agency tweet databases in one list
allreplies = list()

# cycle through handles and save tweets to allreplies
for (i in 24:nrow(handles)) {
  print(handles$twitter_handle[i])
  repliestweets = get_all_tweets(
    reply_to = substring(handles$twitter_handle[i], 2),
    start_tweets = "2007-01-01T00:00:00Z",
    end_tweets = "2021-12-31T00:00:00Z",
    bearer_token = get_bearer(),
    data_path = "data_replies_3",
    bind_tweets = T,
    n = 1000000
  )
  repliestweets$agencyhandle = handles$twitter_handle[i]
  repliestweets$agencyname = handles$acronym[i]
  allreplies[[i]] = repliestweets
}

# EURightsAgency does not work for some reason (no 23) skipped it for now
save(allreplies, file = "all_replies_3")



replytweets = list()
for(f in 1:length(allreplies)){
  temporary = allreplies[[f]]
  print(temporary$agencyname)
  temporary$referenced_type = "no reference"
  temporary$referenced_id = 0
  for(i in 1:nrow(temporary)){
    temporary$referenced_type[i] = ifelse(is.null(temporary$referenced_tweets[i][[1]])==F, temporary$referenced_tweets[i][[1]]$type, 0)
    temporary$referenced_id[i] = ifelse(is.null(temporary$referenced_tweets[i][[1]])==F, temporary$referenced_tweets[i][[1]]$id, 0)
    replytweets[[f]] = temporary
  }
}
save(replytweets, file="replytweets.Rdata")
```

#Legacy code
```{r}

# before collecting audience tweets, lets check how many audience tweetw there actually are - we do not want to get rate locked. 
#audiencecounts = list()
audiencecounts2=list() # Frontex and SRB did not work the first time, so we add them now. 

for (i in 24:nrow(handles)) {
  print(handles$twitter_handle[i])
  allcounts = count_all_tweets(
    query = handles$twitter_handle[i],
    start_tweets = "2010-01-01T00:00:00Z",
    end_tweets = "2021-09-01T00:00:00Z",
    bearer_token = get_bearer(),
    data_path = "data_tweets_audiences2",
    n = 1000000
  )
  allcounts$agencyhandle = handles$twitter_handle[i]
  allcounts$agencyname = handles$acronym[i]
  audiencecounts2[[i]] = allcounts
}

# add Frontex and SRB to the original file (audiencecounts)
load("audiencecounts")
audiencecounts[[24]] = audiencecounts2[[24]]
audiencecounts[[25]] = audiencecounts2[[25]]

save(audiencecounts, file="audiencecounts_updated")


###################################################################
#store all audience tweet databases in one list
audiencetweets = list()


#cycle through handles and save tweets to alltweets
#for (i in 1:nrow(handles)) {
  print(handles$twitter_handle[i])
  agencytweets = get_all_tweets(
    query = handles$twitter_handle[i],
    start_tweets = "2010-01-01T00:00:00Z",
    end_tweets = "2021-09-01T00:00:00Z",
    bearer_token = get_bearer(),
    data_path = "data_tweets_audiences",
    bind_tweets = T,
    n = 100000
  )
  agencytweets$agencyhandle = handles$twitter_handle[i]
  agencytweets$agencyname = handles$acronym[i]
  alltweets[[i]] = agencytweets
}

#efsa timeline
#test = get_all_tweets(user="Food_EU",
               start_tweets = "2013-01-01T00:00:00Z",
               end_tweets = "2021-06-01T00:00:00Z",
               bearer_token = get_bearer(),
               data_path = "data",
               bind_tweets = T,
               n=10000)
#save(test, file="EFSAtweets")
load(file="EFSAtweets")
#get tweets from people addressing efsa
#test = get_all_tweets(query="@Food_EU",
               start_tweets = "2013-01-01T00:00:00Z",
               end_tweets = "2021-06-01T00:00:00Z",
               bearer_token = get_bearer(),
               data_path = "data",
               bind_tweets = T,
               n=10000)

# count tweet volume that addresses EFSAs account
EFSA_tweetcounts = count_all_tweets(query="@Food_EU",
               start_tweets = "2014-11-28T00:00:00Z",
               end_tweets = "2021-06-01T00:00:00Z",
               bearer_token = get_bearer(),
               n=1000000)

```
# Bind all tweets to a dataframe
```{r}
test$referenced_type = "no reference"
test$referenced_id = 0

for(i in 1:nrow(test)){
  test$referenced_type[i] = ifelse(is.null(test$referenced_tweets[i][[1]])==F, test$referenced_tweets[i][[1]]$type, 0)
  test$referenced_id[i] = ifelse(is.null(test$referenced_tweets[i][[1]])==F, test$referenced_tweets[i][[1]]$id, 0)
}

# now for the whole list of tweets
tweets = list()
for(f in 1:length(alltweets)){
  temporary = alltweets[[f]]
  temporary$referenced_type = "no reference"
  temporary$referenced_id = 0
  for(i in 1:nrow(test)){
    temporary$referenced_type[i] = ifelse(is.null(temporary$referenced_tweets[i][[1]])==F, temporary$referenced_tweets[i][[1]]$type, 0)
    temporary$referenced_id[i] = ifelse(is.null(temporary$referenced_tweets[i][[1]])==F, temporary$referenced_tweets[i][[1]]$id, 0)
    tweets[[f]] = temporary
  }
}

save(tweets, file="tweets")
```

